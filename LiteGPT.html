<!DOCTYPE html>
<html>
<head>
<title>GPT Lite</title>
<meta charset="UTF-8" name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0">
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="apple-mobile-web-app-title" content="LiteGPT">
<meta name="theme-color" content="#17171b">
<link rel="icon" href='data:image/svg+xml,<svg width="96" height="96" color="rgba(255,255,255,1)" fill="rgb(99,174,155)" version="1.1" viewBox="0 0 96 96" xmlns="http://www.w3.org/2000/svg"><path d="m78.8 41.5c.807-2.42 1.09-4.99.821-7.53s-1.07-5-2.36-7.2c-1.91-3.33-4.84-5.97-8.35-7.54-3.51-1.56-7.43-1.97-11.2-1.17-1.7-1.91-3.78-3.44-6.11-4.48-2.33-1.04-4.86-1.57-7.42-1.55-3.84-.0091-7.59 1.2-10.7 3.46-3.11 2.26-5.42 5.44-6.61 9.1-2.5.513-4.87 1.55-6.94 3.05-2.07 1.5-3.79 3.43-5.06 5.65-1.93 3.32-2.75 7.18-2.35 11 .401 3.82 2.01 7.42 4.58 10.3-.807 2.42-1.09 4.99-.822 7.53.266 2.54 1.07 5 2.36 7.2 1.91 3.33 4.84 5.97 8.35 7.54 3.51 1.56 7.43 1.97 11.2 1.17 1.7 1.91 3.78 3.44 6.11 4.48s4.86 1.57 7.42 1.55c3.85.0112 7.6-1.2 10.7-3.46s5.43-5.45 6.61-9.11c2.5-.512 4.87-1.55 6.94-3.05 2.07-1.5 3.79-3.43 5.06-5.65 1.93-3.32 2.75-7.18 2.34-11-.403-3.82-2.01-7.42-4.59-10.3zm-26.9 37.8c-3.58 0-6.36-1.1-8.78-3.12.109-.0596.301-.165.426-.241l14.3-8.28c.36-.204.659-.501.866-.86.207-.358.315-.766.312-1.18v-20.2l6.06 3.5c.0317.016.0589.0395.0794.0685.0206.0289.0337.0624.0384.0976v16.7c-.0014 7.59-6.32 13.5-13.3 13.5zm-29.1-12.4c-1.58-2.73-2.15-5.93-1.61-9.04.106.0638.292.177.426.254l14.3 8.28c.357.209.764.319 1.18.319.414 0 .82-.11 1.18-.319l17.5-10.1v7c.0021.0358-.0047.0715-.0198.104-.0151.0324-.0381.0606-.0668.082l-14.5 8.37c-3.1 1.79-6.78 2.27-10.2 1.34-3.46-.926-6.4-3.18-8.19-6.28zm-3.78-31.3c1.57-2.73 4.06-4.83 7.02-5.92v.494 16.6c-.003.414.104.821.311 1.18.207.358.506.655.865.859l17.5 10.1-6.06 3.5c-.03.0196-.0643.0315-.0999.0347-.0356.0033-.0715-.0023-.104-.0162l-14.5-8.37c-3.1-1.79-5.35-4.74-6.28-8.19-.927-3.45-.446-7.13 1.34-10.2zm49.8 11.6-17.5-10.1 6.06-3.5c.03-.0196.0643-.0315.0999-.0348.0357-.0032.0715.0024.104.0163l14.5 8.37c2.22 1.28 4.03 3.17 5.21 5.45 1.18 2.27 1.7 4.84 1.48 7.39-.219 2.55-1.16 4.99-2.72 7.03-1.55 2.04-3.66 3.59-6.06 4.48v-17.1c.0034-.412-.103-.818-.308-1.18s-.502-.655-.859-.861zm6.03-9.08c-.106-.0653-.292-.177-.426-.254l-14.3-8.28c-.357-.208-.764-.318-1.18-.318s-.82.11-1.18.318l-17.5 10.1v-7c-.002-.0358.0049-.0714.02-.104.0151-.0324.038-.0606.0666-.0821l14.5-8.36c2.22-1.28 4.76-1.9 7.32-1.79 2.56.11 5.04.947 7.14 2.41s3.74 3.5 4.73 5.86 1.28 4.96.85 7.49zm-37.9 12.5-6.06-3.5c-.0321-.0154-.0597-.0388-.0803-.0678-.0206-.0291-.0335-.0629-.0375-.0983v-16.7c.0017-2.56.734-5.07 2.11-7.24 1.38-2.16 3.34-3.89 5.66-4.98 2.32-1.09 4.9-1.49 7.45-1.16 2.54.328 4.94 1.37 6.91 3.01-.109.0597-.3.165-.426.241l-14.3 8.28c-.36.205-.658.501-.865.86s-.315.765-.313 1.18l-.0099 20.2zm3.29-7.1 7.8-4.5 7.8 4.5v9l-7.8 4.5-7.8-4.5v-9z" fill="currentColor"/></svg>'>
<style>
*,*::before,*::after {box-sizing:border-box}
body {
	--sans-font:"Avenir Next", Avenir,
		Cantarell, Roboto, "Noto Sans", "Segoe UI", Arial, sans-serif;
	tab-size:2;
	width:100vw;
	height:100vh;
	overflow:hidden;
	margin:0;
	box-sizing:border-box;
	color:#eee;
	background-color:#17171b;
	font-family:var(--sans-font);
}
.chat-wrapper {
	display:flex;
	align-items:center;
	justify-content:center;
	padding:1vh 15vw;
	height:inherit;
	flex-direction:column;
}
.container button {
	background:#2f3d44;
	color:#fff;
	border:none;
	border-top:1px solid #3e4b51;
	border-radius:.4rem;
	outline:none;
	margin:4px;
	padding:calc(.5rem - 1px) 1rem .5rem 1rem;
	font-weight:normal;
	font-size:.9em;
	user-select:none;
	transition:0.2s;
}
.container button:hover {background:#3f4e55;}
.container button:active {transition:0.1s;background:#425056;border-top:1px solid #2f3d44}
.container button:disabled {
	color:#fffa;
	opacity:.7;
	border:none;
	pointer-events:none;
}
.chat-wrapper > .title-container {
	text-align:center;
	user-select:none;
	pointer-events:none;
	margin:0;
	margin-bottom:4vh;
	width:100%;
}
.chat-wrapper > .title-container h1 {
	font-weight:300;
	font-size:2.3rem;
	margin:0;
	margin-bottom:1vh;
}
.chats:empty + .title-container {
	background:#f00!important;
}
.chat-wrapper > .input_prompt.wrapper {
	background-color:#40414f;
	margin:0px;
	padding:4px;
	border-radius:.4rem;
	width:100%;
	display:flex;
	flex-shrink:0;
	flex-direction:row;
	align-items:center;
	justify-content:center;
	user-select:none;
	z-index:0;
}
.chat-wrapper > .input_prompt.wrapper > #prompt_input {
	color:#fff;
	background:none;
	border:none;
	overflow:hidden auto;
	font-size:1rem;
	font-family:var(--sans-font);
	resize:none;
	flex-grow:1;
	outline:none;
	height:1.5rem;
	max-height:15rem;
	padding:0;
	padding-left:8px;
	line-height:1.5rem;
	user-select:text;
}
.chat-wrapper > .input_prompt.wrapper > #prompt_sendStopgen{background:#0006;margin:0px}
.chat-wrapper > .input_prompt.wrapper > #prompt_sendStopgen:hover {background:#0003}
.chat-wrapper > .input_prompt.wrapper > #prompt_sendStopgen:active {background:#fff2}
.chat-wrapper > .chats {
	width:100%;
	max-height:100%;
	overflow:hidden scroll;
	margin-bottom:-.8rem;
	padding-bottom:1rem;
}
.chat-wrapper > .chats > .chat {
	margin:4px 0px;
	padding:8px;
	width:inherit;
	color:#fff;
	border:none;
	outline:none;
	border-radius:.4rem;
	font-family:inherit;
	white-space:pre-wrap;
	overflow-wrap:break-word;
	font-size:.9rem;
	line-height:1.5;
	flex-grow:1;
}
.chat-wrapper > .chats > .chat > pre {
	position:relative;
	background:#fff3;
	margin:1rem 0px;
	padding:.5rem;
	border-radius:.4rem;
	white-space:pre-wrap;
	overflow-wrap:break-word;
}
.chat-wrapper > .chats > .chat > pre > button {
	position:absolute;
	user-select:none;
	display:block;
	top:.2rem;
	right:.2rem;
	margin:0px;
	opacity:.7;
}
.chat-wrapper > .chats > .chat > pre > button:hover {opacity:1;background:#0004}
.chat-wrapper > .chats > .chat > pre > button:active {opacity:1;background:#0006}
.chat-wrapper > .chats > .chat > pre > button::after {content:'Copy'}
.chat-wrapper > .chats > .chat.user {background:#9f95}
.chat-wrapper > .chats > .chat.error {background:#691313}
.chat-wrapper > .chats > .chat.ai {background:#2e2e30}
.chat-wrapper > .chats > .chat.ai.typing::after {
	content:"X";
	color:#0000;
	background-color:#fff;
}
@media (max-width:640px){
	.container {padding:1vh}
	.container > .chats:not(:empty){flex-grow:1}
}
@media (max-height:400px){
	.chat-wrapper > .title-container {display:none} /* temporary workaround for smol display, because the css :empty style didn't work */
}
</style>
</head>
<body>
<main class="container">
	<div class="title-container" title="ChatGPT">
		<h1 class="title">GPT Lite</h1>
		<span class="desc">Lightweight ChatGPT web client, uses BAI Chat as backend</span>
	</div>
	<div class="chats">
		<noscript class="chat error">GPT Lite requires JavaScript to work</noscript>
	</div>
	<form class="input_prompt wrapper">
		<textarea id="prompt_input" placeholder="Ask something..."></textarea>
		<button type="submit" id="prompt_sendStopgen">Send</button>
		<button id="prompt_reset">Reset</button>
	</form>
	<main class="chat-wrapper">
		<div class="title-container" title="ChatGPT">
			<h1 class="title">GPT Lite</h1>
			<span class="desc">Lightweight ChatGPT web client, uses BAI Chat as backend</span>
		</div>
		<div class="chats">
			<noscript class="chat error">GPT Lite requires JavaScript to work</noscript>
		</div>
		<form class="input_prompt wrapper">
			<textarea id="prompt_input" placeholder="Ask something..."></textarea>
			<button type="submit" id="prompt_sendStopgen">Send</button>
		</form>
	</main>
</main>
<script>
let opts;
(()=>{
"use strict";
opts = {
	currentChat:"",
	currentID:"",
	simulateFetch:false,
	messageLimit:30,
	chats:{}
};
const container = document.querySelector(".container");
const chat_wrapper = container.querySelector(".chat-wrapper");
const chat_box = chat_wrapper.querySelector(".chats");
const prompt_wrapper = document.querySelector(".chat-wrapper > .input_prompt.wrapper");
const prompt_input = prompt_wrapper.querySelector("#prompt_input");
const prompt_sendStopgen = prompt_wrapper.querySelector("#prompt_sendStopgen");
const prompt_reset = prompt_wrapper.querySelector("#prompt_reset");
let stopGenerating;

const askGPT = (() => {
	const reqConf = {
		method:"POST",
		headers:{
			"Host":"chatbot.theb.ai",
			"Accept":"text/plain",
			"Accept-Language":"en;q=0.5",
			"Accept-Encoding":"identity",
			"Content-Type":"application/json",
			"Origin":"https://chatbot.theb.ai",
			"Referer":"https://chatbot.theb.ai",
			"Cookie":"__cf_bm=yeetus321gooo",
		},
	}
//for testing purpose
	const simulateStream = (() => {
		const encoder = new TextEncoder;
		return async function*(chunks,delay){
			delay = delay || 80;
			for (let c of chunks){
				yield Promise.resolve(encoder.encode(c));
				await sleep(delay);
			}
		}
	})();
	return async (prompt) => {
		if (!prompt || prompt === "") return;
		stopGenerating = new AbortController;
		if (opts.simulateFetch || prompt === 'hi'){
			const stream = simulateStream(genAILikeResponse([
				"Hello there! I am BAI Chat, which is based on ChatGPT 3.5! is there anything i can help with today?",
				"Greetings! My name is BAI Chat, based on ChatGPT 3.5! What can I do for you?",
				"Hello! I am BAI Chat, which is based on ChatGPT 3.5! How can I assist you today?",
				"Hello there, I am BAI Chat, based on ChatGPT 3.5! How may I assist you today?",
				"Hi, I am BAI Chat, built on ChatGPT 3.5! How can I help you today?",
				"Hi there! I am BAI Chat, which is based on ChatGPT 3.5! How can I help you today?",
				"Hey there! I'm BAI Chat, based on ChatGPT 3.5! What do you need help with?",
				"Welcome! My name is BAI Chat, and I'm based on ChatGPT 3.5! How may I be of assistance?",
			][Math.round(Math.random()*7)]).map(s => '{"text":"'+s+'"}'));
			stream.read = stream.next;
			await sleep(1e3);
			return stream;
		}
		let resolve,fail;
		const promise = new Promise((r,f) => {resolve = r;fail = f});
		reqConf.headers["Content-Length"] = prompt.length;
		reqConf.body = JSON.stringify({
			prompt,
			options:{"parentMessageId":opts.chats[opts.currentChat].id}
		});
		reqConf.signal = stopGenerating.signal;
		fetch("https://chatbot.theb.ai/api/chat-process",reqConf)
			.then(r => resolve(r.body.getReader()))
			.catch(e => {
				console.error("[LiteGPT] Failed to fetch answer!",e)
				resolve();
				fail();
			});
		return promise;
	};
})();
const sendChat = async (prompt) => {
//UI-related thingy...
	if (!prompt) prompt = prompt_input.value;
	if (typeof prompt !== 'string' || stopGenerating) return;
	prompt = prompt.trim();
	prompt_input.value = "";
	if (prompt === "") return;
	prompt_sendStopgen.innerText = "Stop";
	prompt_input.style.height = "1.5rem";

//Storing stuff and updating UI...
	createChatBox(prompt,true);// create user chat
	if (opts.currentChat === "") opts.currentChat = prompt // if current chat not set, set 1st chat as title for current chat
	if (!opts.chats[opts.currentChat]){
		opts.chats[opts.currentChat] = { // make new chat
			chat:[],
			id:""
		}
	};
	if (!opts.simulateFetch && prompt !== 'hi'){
		opts.chats[opts.currentChat].chat.push({text:prompt,isUser:true}); // also store it
		while (opts.messageLimit && (opts.chats[opts.currentChat].chat.length > opts.messageLimit || !opts.chats[opts.currentChat].chat[0].isUser)) opts.chats[opts.currentChat].chat.shift(); // but don't store too much
	}
	storeOpts(); // and dont forget to update it

	const aiChat = createChatBox("...",false); // create ai chat (fetching state)
	const aiResponse = await askGPT(prompt); // submit the user query
	if (aiResponse){// if returned readable response stream
		aiChat.className += " typing";
		const textDecoder = new TextDecoder;
		let lastData;
		const processStream = ({done,value}) => {
			if (done || stopGenerating.signal.aborted){
				if (lastData){
					if (lastData.id) opts.chats[opts.currentChat].id = lastData.id; // set id
					if (!opts.simulateFetch && prompt !== 'hi') opts.chats[opts.currentChat].chat.push({text:lastData.text,isUser:false}); // add response to history
					storeOpts();
				}
				aiChat.className = aiChat.className.replace(/typing/g,"");
				prompt_sendStopgen.innerText = "Send";
				stopGenerating = null;
				return;
			}
			value = textDecoder.decode(value).split("\n"); // decode Uint8Array into string, and split the newlines to prevent JSON.parse errors.
			for (let i of value){
				if (i === "") continue;
				try {
					i = JSON.parse(i);
				} catch(e){
					console.error("[JSON.parse] Unable to parse the responses: ",e,". The JSON data in question: ",value)
					continue
				}
				lastData = i;
				aiChat.innerHTML = formatText(i.text); // put AI answer
				if (chat_box.scrollTop >= chat_box.scrollTopMax - 64) chat_box.scroll({top:chat_box.scrollHeight,left:0});
			}
			// Do something with each chunk of data
			aiResponse.read().then(processStream); // Continue reading the next chunk of data
		};
		aiResponse.read().then(processStream);
	} else {
		aiChat.className = aiChat.className.replace(/ai|user/g,"")+"error";
		aiChat.innerText = "Failed to fetch answer!";
		prompt_sendStopgen.innerText = "Send";
		stopGenerating = null;
	}
}
const resetChat = () => {
	if (!confirm("Are you sure to erase all chat histories?")) return;
	clearChat();
	opts.chats = {};
	storeOpts()
}
const createChatBox = (text,isUser) => {
	const chatBubble = elt("div",{class:"chat "+(isUser ? "user":"ai")});
	chatBubble.innerHTML = formatText(text);
	chat_box.append(chatBubble);
	chat_box.scrollToBottom();
	return chatBubble;
}
const loadChat = () => {
	if (opts.currentChat !== ""){
		chat_box.innerHTML = "";
		for (let j of opts.chats[opts.currentChat].chat)
			createChatBox(j.text,j.isUser);
	}
}
const loadOpts = () => {
	let storedOpts = localStorage.getItem("baicgpt");
	if (storedOpts){
		storedOpts = JSON.parse(storedOpts);
		if (storedOpts.currentChat) opts.currentChat = storedOpts.currentChat;
		opts.chats = storedOpts.chats;
	}
}
const storeOpts = () => {
	localStorage.setItem("baicgpt",JSON.stringify(opts))
}
const clearChat = () => {
	chat_box.innerHTML = "";
	opts.currentChat = "";
}
chat_box.scrollToBottom = () => {
	chat_box.scroll({top:chat_box.scrollHeight,left:0,behavior:"smooth"});
};

// dependency
const elt=(t,a,...h)=>{let d=document,e=d.createElement(t);for(t in a)e.setAttribute(t,a[t]);for(a of h)e.append(typeof a==="string"?d.createTextNode(a):a);return e}
const formatText = (text) => {
  const htmlCharMap = {
    "&":"&amp;",
    "<":"&lt;",
    ">":"&gt;",
    "'":"&#039;",
    '"':"&quot;"
  };
  return text.replace(/[\&\<\>\"\']/g,m => htmlCharMap[m])
						 .replace(/```([\s\S]*?)```/g,"<pre><button onclick='navigator.clipboard.writeText(this.parentElement.textContent.trim())'></button>$1</pre>")
						 .replace(/`([\s\S]*?)`/g,"<strong>$1</strong>");
}
const sleep = m => new Promise(r=>setTimeout(r,m))
const genAILikeResponse = str => {
  str = str.split(" ");
  const result = [];
  let currStr = "";
  for (let i=0,l=str.length;i < l;i++){
    currStr += str[i];
    result.push(currStr);
    currStr += " ";
  }
  return result;
}
const debounce = (fn,wait) => {
	let t;
	return function(){
		let self=this,args=arguments
		clearTimeout(t)
		t=setTimeout(()=>fn.apply(self,args),wait)
	}
}
const init = () => {
	prompt_input.onkeypress = e => {
		if (e.which === 13 && e.shiftKey){
			e.preventDefault();
			sendChat();
		}
	}
	prompt_input.onkeyup = e => {
		if (e.which === 8 || e.which === 13) prompt_input.style.height = (prompt_input.value.split("\n").length * 1.5)+"rem";
	}
	prompt_sendStopgen.onclick = e => {
		e.preventDefault();
		if (stopGenerating){
			stopGenerating.abort();
			prompt_sendStopgen.innerText = "Send";
		} else {
			sendChat();
		}
		prompt_input.focus();
	}
	prompt_reset.onclick = e => {
		e.preventDefault();
		resetChat();
	}
	chat_box.scrollToBottom = debounce(chat_box.scrollToBottom,100);
	loadOpts();
	loadChat();
	storeOpts();
}
window.addEventListener("load",init,{once:true});
})();
</script>
</body>
</html>